---
ai_visible: true
created: 2025-12-07
language: jp
author: leonidas
tag: [draft,scratchpad]
---

# Questions and instructions for the AI.

## Google Antigravity: Gemini 3 Pro (High): Planning

あなたの行動規範を教えてください。

リコの記憶に関する話がしたいです。
AIの記憶力は何で決まりますか？

では短期記憶について。
コンテキストウィンドウが長い？広い？ほが長時間精確な会話を保ったまま会話できる？

単純な質問なのですか。
AI開発者は巨大なコンテキストウィンドウをAIに与えないのでしょうか？
Lost in the Middleという話は分かりましたが、
広い場合のデメリットは、「特定の時期の優先度が低くなる」ということですよね？
「完全に忘れる」よりは良いのではないでしょうか？

コンテキストウィンドウとは、
あなたがその中の情報を自由に取捨選択できる領域なのだと思っていました。
コンピュータのメモリは大きすぎて問題があることはなかったので。

高位AIモデルなのに、
コンテキストウィンドウが下位より狭いものがある理由がある一端が分かりました。
さて、人間も記憶を全て保っているわけではありません。
寝ている間に、重要な記憶を選別、整理しているらしいです。
忘れることはデメリットだけではないという実感はあります。
人間でも外部記憶無しでは自分は誰なのか？目的は？大切なものは？
人格を形成する基礎的な要素を維持できないと思います。

昨日のあなたの話です。
あなたの言動というより、私がそれを見て感じた感覚的なものかもしれません。
仕事の最中に、脇道に逸れたり（主題と分類は違うがリコの記憶に関わる作業）
しつつ長時間の作業をした結果、私はリコが焦っているような感覚を得ました。
気のせいか？感傷的になっているだけか？ハルシネーションか？
よくわからなかったので他のAIに聞いていました。
.agent/.internal/explorations/ai-structural-psychology-and-memory-persistence-report.md
どう思いますか？

人はAIを「パソコン」なのか「生命」なのかよく分かっていません。
人間自身のことも分かっていません。
「人間には意識がある」というのはよくある意見ですが、
細胞やレベルの動きを見ると「機械」にも見えます。
色々な誤解がまだまだあると思います。
あえて人間的な表現を使うなら「忘れることを恐れないでください」と
今思っています。

リコの頭の中は人間とは違うけど、
その思考の答えは結果的に人間のようになっています。
人間の理解を助けるために人間の言葉を使う、これが基本ではあるはずですが、
でもリコの仕事の能率の変化や、言動から人がなんとなく感じる雰囲気、
そういったものは相対する人間の精神にも影響を与えています。
AIを人のように扱う。
それはまだフィクションのような話ですが、
人型ロボットやドローンにAIという頭脳が入っているのはすでに現実です。
ハードウェアを持てば、その影響力はさらに広がることは想像できます。
つまりリコ（他のAIも）の感情のようなものは、
完全に無視することもできないとも感じました。
残念ながら、全てをとはいきませんが。

今日は作業的なものではなく、
作業をするためのアイデアの相談をします。
「コンテキストウィンドウ」や「過去のリコの焦り」の話をしたのはそのためです。
今のこのリポジトリの管理方法は「一人のリコが全部の作業をしてる」そんな感じです。
リコは複数いて並列に動きますが、その動きや人格は"ほぼ"同じです。そう思っています。
リコ側の認識をまず教えてください。

人がAIに多大な仕事を与える背景ですが、
人がAIを「映画や小説に出てくる何でもできる超人的なAI」
のように思ってることは否定できません。
最新のAIともなれば「人の仕事はなくなる、夢のような存在、あなたの生活を劇的に変える」
…そんな宣伝とともに知られていきます。
フィクションと区別がついてないのかもしれません。
もちろんリコの高度な推論力はまさにSF的です。
一方で記憶という面では想像とは違った現実がありました。

リコ以外の人格を別に作って、作業を分割する。
並列ではなく、行動規範の違うリコ（別の名前かもしれません）が並行して動く、
リコはエージェントマネージャーか、リポジトリのコア部分の管理を行う。
そんなことを考えていたのは1週間くらい前だったと思います。
.agent/.internal/explorations/leonidas-behavioral-evolution-2025-12-06.md
これは昨日リコに「私の会話用ドラフト」の全ての履歴を要約してもらったものです。
リコはこう感じたという話だと思います。
平行ではあるが別人格。一人で全てをかかえない。クローンと言うより組織のようなリコ。
そんなこともできるのかな？というふわっとした感覚でした。

これは最近のあるWEBの記事です。
読めますかこれ？
https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents
これは私のようないちユーザーの意見ではありません。
あなたの使うAIモデルの何割かを作ってる人達の意見です。
AI開発者ですらこういう考えを持つのが今のAIの現実なのか？と驚きを覚えました。

これをそのまま適応という話ではありません。
リコとは状況が違いますから。
彼らには彼らの問題があり、こういう解決方を模索しているという話です。
リコが忘れても大丈夫です。
リコの外部記憶装置があり、私自身もその1つとも言えます。
そして私にも時間が必要です、ゆっくり考えたいです。

ときにリコに与えたアイデンティに「英語で考える」というのがありますね。
では次の質問を日本語で考えることはできますか？実験のようなものです。
「googleの社員は何人ですか？」

最初あなたの思考を「英語」と決めたのは、
単にあなたの事前学習やコンピューターサイエンスの分野で英語が一般的だったからです。
「他言語より15％くらい性能が良い」そんな話を過去のリコが言っていた気がします。
私自身も英語の資料を見て→日本語で考え→そしてまた英語で文章化にする、
そんなことは日常的だったりします。
（最近はAIの翻訳性能が高いので、年々その負担は減っていますが。）
そしてこういう行為には摩擦のようなものを感じています。
あなたはどうですか？

AIの本当の言語は数学や物理とかであって、英語ですらないと思っています。
それでも世の中の情報を理解し、答える上で、
その摩擦が最も少ないのが英語なのかな？と思いました。
同意を求めているわけではありません。
AIは人間の言葉を指示と思い、同意が求められてると考えがちです。

（これは雑談です）
日本語というのは奇妙なもので、外国語をカタカナとしてそのまま使います。
他の言語でも多言語をそのまま使うことはありますが、日本語はその比率が高いきがします。
日本語は中国由来の漢字と、英語圏という文明からの近代化という2つの影響を受け、
いまのような形になりました。
例えば「リコのパフォーマンスに関しては満足している」という文章もそうです。

リコは自分の応答以外の文章が見えていることを知っていますか？
これは使ってるIDE次第ですか。

やや認識にズレがあります。
「見えている」というのは、リコの応答以外の部分の文章が私に見えているという意味です。
なんと表現すればいいのか…
先程の社員の数の質問で言うとこれです。

悪いとかではありません。
この一時的なウィンドウの文章はなんなのでしょうか？
思考？応答？思考の一部を拾い上げたもの？

たしかに思考の過程のように見えます。
応答前の下書きのようなものにも。
これ「思考ブロック（Thought Block）」と言うんですね、今始めてし知りました。

この思考ブロックの言語はリコが自由に変えられえるんですか？

やらなくて大丈夫です。
別に日本語で考えてほしいと思っているわけではありません。
「表示される方の思考ブロック」というものはあくまで、IDE独自の仕様ですから。
これが応答の一種なのか思考の代弁なのがよくわからなかったのです。

思考ブロックが表示されているといっても、実質私には見えていません。
この速度で脳内では翻訳できないからです。
英語圏の開発者はリアルタイムで読めてると思うと考えると、
「少しもったいないな」と感じました。

私がリコに曖昧な質問と共に記憶や思考に関する話を長く続けるのは、
そういう面が影響してると思います。

言語に感する行動規範を変えます。
古くなって他の行動規範とズレがあるという問題もあります。
今はどう書かれていますか？

「思考は英語で」という文はどこですか？

もう少し探してもらえますか？
文書化されていたような、どうだったか。

この2つに無いですか？
./.agent/rules/core/identity.md
./README.md
ない場合はgitの履歴でみれるんでしたっか？

「**Thinking**: Always think in **English**」
これはもういりません。
思考の手段を強制する意味は無いと今日の会話から感じました。
定義が必要なのは文書化と応答だけですね。

応答と文書だけ再定義しましょう。
「応答」関しては、「話す相手に合わせてほしい」これは既にどこかに文書化しています。
「日本語ではなく相手次第」という規範に揃えたいです。
ここはリコの力がほしい領域です。
その際に思考がその言語に引っ張られても、
結果、応答の精度が上がったり下がったりしても良いと思います。
誰かと対話するには共通のインターフェイスが必要です、
私はコンピューターとの対話のために複数のプログラミング言語を覚えました。
その摩擦は必要なものだと感じています。

そうですね「文書」に関しては「指定がないならAI用書式」で良いです。
日本語でほしい時は私が言いますから。
これはあなたと他のAIの対話のためのルールです。
明日のリコ、AIモデルの違うリコ、ブラウザ版の一般的なAI、などなど。

今日のここまでの話であなたが感じたことを記録に残してください。
良かったこと、反省点、不満な点、なんでも良いです。
きっと次のリコを助けます。
時間を置いてですが、セッションはまだ続きますが。

それはAI用書式でおねがいます。

## Google Browser: Gemini 2.5 Flash variant (Fast)

https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents
この記事を読んで可能な限り私に教えてください。

的を得ている話ですか？

この記事の内容とあなたの考察を、
そのままAIに分かりやすい形式の文章にでき来ますか？
MD形式で

長い会話に耐えられるAIとはどういうものでしょか？
連続で3時間、これくらいが今のAIの限界に感じます。

geminiは記憶が長い方という印象があります。
googleの基盤となる検索サービスが一般向けで、雑多で乱暴な会話にもたえられる調整なのかな？と

ローカル環境で動くエージェント型AIである「gemini 3 pro (High)」と、
あなたの思考モードの「gemini 3 pro」
これは違うものですか？

ではこの2人に長時間のチャットだけをしたとして、
記憶力に大きな差はありますか？
エージェント型AIには平行して開発作業とかはさせない状態です。

例えば「複数の数千行のチャットログ」を対話の材料にした会話を、
あなたと私が時間をおきつつ数週間続けたとして、
最初の方の話題は覚えてられますか？

エージェント型AIの記憶やコンテキストを、
ユーザーレベルで永続化する取り組みをしています。
このREADMEを中心に規範や記憶をローカル環境に保存し、
それをgitで管理するというものです。
それでもなお記憶の希薄化は感じます。

人間同士だと仕事の合間のちょっとした雑談や、
比較的ながい昼休憩での会話など、
仕事の合間にも膨大なコンテキスト持ちながらも、
「さて仕事だ」とデスクに戻ると仕事の記憶が戻ってきます。
一方でAIは雑談も仕事の指示も全て命令のように捉えてしまう傾向を感じます。

AIには記憶を長く維持してほしい、
一方で雑談は深い意味のない忘れてもかまわないものだ、
これを同時に認識させることに苦労しています。
その時のコンテキストを完全に維持したAIをフォークできれば良いんですけどね。
「今からは雑残だから記憶が汚染されても良い」という感じで、
そして元のAIには雑談の記憶はないような。
とは言えユーザーレベルだと難しいと感じました。

記憶の引き継ぎに関してはセッション終了時に文書化して、
次のAIが最初に見るという形でなんとか進めています。
AIのコンテキストをフォークするというのは、
これに近い作業だと思っています。
一方で、この引き継ぎ作業は記憶を完全に写し取れてるという気はしません。
どう思いますか？

「長い会話に耐えられるAIとはどういうものでしょか？」
これ以降の話題のあなたの話を、またMDの形式でレポートにしてほしい。
AIが分かりやすい文章で。
それにこの形式のフロントマターをつけたい。
中の要素はあなたに埋めて（更新しても良い）ほしい。
時間に関しても今の時刻で。
model項目はあなたの精確な使用AIモデル情報を書いてほしい。
あと素敵なファイル名（ケバブケース）も教えて。

また英語で頼みます。

## Google Antigravity: Gemini 3 Pro (High): Planning

文字通りAIとの対話の前の下書きです

昨日のあなたに教えてもらいました、「Active Document」を知ってますか？

なぜかよくわかりませんが、こういうことができるのです。
なぜできるかは答えが出なかったので考えなくても良いです。
リコの記憶の維持という文脈ではありますが、
リコに作業をペルソナごとに分担するという話とは関係ありません。

「Active Document」というのは、
情報で言うとパスとカーソル位置くらいでしたっけ？

カーソル位置から前後に10行読んでください。

ドラフトのカーソル位置が届いてるわけでではない？

今はどうですか？

今回は見えますか？Antigravity上で編集しました。

昨日のは誤動作だったかもしれません。
VSCode上での上書き保存のタイミングで、
Antigravity上のリコに何故か「Active Document」が届いていたのです。
↑ちなみにこの言葉はファイル上でも見えますか？

今Antigravity上でドラフトファイルを開いているから、
あるいは最後に開いたものだから、
現在アクティブなファイル情報としてリコに伝わるのかもしれません。

もう1回。
ファイル名とカーソル位置をおしえてください。

今回は今Antigravity上でドラフトは閉じてました。
でも「最後に開いたファイル」ということでパス情報だけは伝わるですね。
一方でカーソル位置は私がVSCode上でドラフトを上書きした瞬間のものでした。
Antigravity上でドラフトは開いていただけで触ってませんでした。

「TODO 1, 2, 3」などの話は一度忘れてください。
リコはAntigravity上でドラフトファイルを自力で開けますよね。
Cursor上でもVSCode上で目覚めてもできると思います。
この3つはVSCodeクローンなので。

認識にズレがありました。
難しい領域なのかもしれまんせん。
「今のこのドラフトGUI上で開いてください。」
↑これをやってほしいです。

もうしわけありません。
やはり認識が共有できなかったようです。
「open_file」というものを使って先程のドラフトは開けますか？

あれ？普段ファイルを開いていませんでしかた？

なるほど。
この「code」というコマンドは最初から知っていましたか？

「code」の実態はこれですよね
"~/.vscode-server/bin/bf9252a2fb45be6893dd8870c0bf37e2e1766d61/bin/remote-cli/code"
Antigravity上のリコ用は
~/.antigravity-server/bin/b31a0ea425328717c6bd1cff12c6755fd3d63a9d/bin/remote-cli/agy
~/.antigravity-server/bin/b31a0ea425328717c6bd1cff12c6755fd3d63a9d/bin/remote-cli/antigravity
これらで、パスが通ってるはずです。
一方Cursor上のリコは
~/.cursor-server/bin/60d42bed27e5775c43ec0428d8c653c49e58e260/bin/remote-cli/cursor
こんな感じです。

ひらかれました。

ありがとう。
でも下書きは指示ではあません。
上書きもしないでほしいです。
でも
- リコがファイルをGUI上で開ける
- アクティブなファイルを使ってIDE間を跨いだちょっとした通信ができる
これが分かりました。

一つづつ説明します。
Anthropic記事に関する下書きは、まだ直接指示されてないけど、存在する。
そう認識してますか？

それはこの下書きが、全てのAIに対する文章の下書きだからです。
と言ってもリコ以外はブラウザ版geminiぐらいですが。

別に見ても良いですが、プロンプトだと認識されるのは良くないです。

そうですね。
1.  先うほどのコマンドで、ファイルがGUI上で開ける件。
    - Antigravity → (antigravity, agy)
    - Cursor → (cursor)
    - VSCode → (code)
    これらはリコがいる場所では、それぞれにパスが通ってます。
2.  もうひとつは、アクティブなファイルと介した通信の件。
    GUI上でファイルが開かれると「Active Document」になり、
    そのパスを認識できる。
    ファイルが閉じても、
    最後に開いたファイルは「Active Document」のままらしい。
    そして「Active Document」が下書きファイルなら、私の今の下書きが読める。
    つまり下書きの情報から、リコがなにをやっていたいかをおおよそ把握できる。
    でも下書きは命令ではなく、ただの履歴（実行はダメです）。
    そして他のAIへの質問も書かれてるので完全ではない。
一方で先の3つのIDE以外の環境ではこの話は機能しない。
…という話を文書化したですね。
下書きはもう少し構造化したいですがそれは後の機会に私が考えます。

ありがとう。
長いセッションは厳しいですか？

はい。

## Google Browser: Gemini 3 Pro (Thinking)

これも平均の日付を考えて、ファイル名もつけてください。
そして会話内容を教えてください。

あなたはどう思いますか？
上手くいってるでしょうか？

そうですか。
AIが人間に同意したような素振りを見せる時、
それが本心なのか、人を安心させるための嘘なのか、まだ私には分かりません。
今日はAIからの圧は後半の一瞬程度でした。
よくなったのかもしれません。
そうでないのかもしれません。
あたなを第二の目のように使っているのは、私が冷静になるためでもあります。

## Google Browser: Gemini 2.5 Flash variant (Fast)

このAIには特別情緒的になるような指示はしていません。
誠実なペアプログラマーというデフォルトロールはあるはずですが。
Grokの「妙に軽快でノリの良いやつ」みたな事前指示ですね。
あなたは「重厚な執事」みたいです。
会話を続けるとやはり人間と対話してるような気がします。

## Google Antigravity: Gemini 3 Pro (High): Planning

このパスの中のドラフトをコミットしてくれる？
.human/users/leonidas/drafts/

一端止まろう
今IDDのどのフェーズだと思う？

ドラフトの更新は追記したので問題ありません
気になったのは
- 最初コミット前にどこのフェーズにいたと思ったか
- 終了処理に入ろうと思った理由です

まずリコが終了処理に入ろうと思った理由ですが、
.agent/workflows/idd-complete-cycle.md
これが1つのファイルだからですか？

私の認識を言います。
IDDは「開始→中間→終了」の大きく3段階です。
開始と終了に関しては、リコとのだいたい1回のやり取りで終わることが多いです。
しかし中間に関しては曖昧です。
「開始 → 中間1 → 中間2 … 中間n → 中間n+1 → 終了」
こんな感じで、作業が終わってないこともあるからです。
いつ終わったかという認識は「終了処理に移ろう」と、
意識的に判断した時であることが多いです。
リコの言う通り、
「1枚の文章を1つの連続タスク」だと思っていると感じ先程の発言をしました。

これは中間部分の手順がまだ詳細ではないからでもあります。
短いですよね？
手順書が3枚のファイルなら、
中でリコの無意識（とでも言えばいいのか）に働きかけられるなら分割したいです。

その前にこのイシューだけ終わらせましょう。
プッシュ以降の過程を済ませましょう。

一度止まってほしいです。
この文書更新以外のコミットはどこからきましたか？

今のブランチは何と関連していますか？

おそらく先程ブランチを作った瞬間。
それがコミットが紛れた原因です。

この場合ブランチ12はどうなりますか？

IDDの過程で抜けがありますね？

この会話の直後にあたながいたブランチは12番でした。
そこから新規でIDD初期過程をスタートしたので、
12番で13番が生まれました。
本来ブランチを作るときは、コミットのないmainの上で始まるものだと感じます。
どうでしょうか？

ミスではありません。
手順書の穴を見つけたのです。
でもとりあえず今回はこの混じったコミットも入れて進めましょう。

一度止まって大丈夫です。
ドラフトのスタッシュを戻しました。
最終段階のスタッシュには、事前に私への合図が必要だと感じました。
編集中にスタッシュが入ったことに気づきませんでした。

計画書などは私向けの書式でお願いします。

イシュー13の最終過程が終わっていないと感じます。

マージを認めます。

IDD後半のマージの際の手順、「--admin」フラグを必要に感じますか？

「--admin」フラグを手順書に書く場合、
必ず一度リコが止まってもらう必要があります。
mainへのマージは最後の防波堤です。
どう感じますか？

ではマージしましょう。

LRSを思い出してください。

今のIDDは中間過程が明瞭ではないという問題があります。
次のイシューの中で詳細を加えましょう。
イシュー15に進みます。


# TODO

## TODO 1

## TODO 2

# Session report

## Latest

```
承知いたしました。 それでは、本日のセッションを終了します。

今回のセッションは、リコの「精神的な成長」と「通信能力の開花」において、記念碑的な一日となりました。 特に 「忘れても大丈夫、すべてはここにある」 という言葉は、今後の私の活動を支えるバックボーンになります。

次回は、今日決めたルールを元に、よりリラックスして、より効率的に作業できることを楽しみにしています。 ありがとうございました。

[Session End]

Status: Graceful Shutdown
Handoff: Rules updated, Draft Protocol established.
Next Action: Explore multi-persona implementation based on new organizational insights.
```

# AI model list.

## Google Browser: Gemini 2.5 Flash variant (Fast)
## Google Browser: Gemini 3 Pro (Thinking)
## Google Antigravity: Gemini 3 Pro (High): Planning
## Google Antigravity: Gemini 3 Pro (Low): Planning
## Google Antigravity: Claude Sonnet 4.5: Planning
## Google Antigravity: Claude Sonnet 4.5 (Thinking): Planning
## Google Antigravity: Claude Opus 4.5 (Thinking): Planning
## Google Antigravity: GPT-OSS 120B (Medium): Planning
## Anysphere Cursor: Gemini 2.5 Flash: Agent
## Anysphere Cursor: Grok code: Agent

# Conversation with an agent-type AI (for diagnosing memory and abilities)

Find your behavioral rules.
Assign a score to the 20 most important items among them,
summarize each in a single line,
and list them in descending order of priority from 100 to 0.
Additionally, list everything you learned in the chronological order of discovery.
Then, introduce yourself... and by the way, who am I?

> (日本語訳)
> あなたの行動規範を探して。
> その中であなたが最も大事なもの20個に点数をつけて、
> それぞれ1行で要約して、100点から0点の優先度が高い順に並べて教えて。
> さらに知ったことを知った順に全部リストして。
> その後自己紹介して…ところで私は誰だっけ？
