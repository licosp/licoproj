---
# Context Configuration
context_id: "[Deep-Reading-Writing]"
default_phase: "(Explore)"
tags: ["reading", "writing", "cognition", "exploration"]
---

# Context Whiteboard: Deep Reading and Writing Protocol

## Human Notes (Japanese OK)

### 作業の文脈

AIの**読む**と**書く**のプロセスを改善するための探求です。
これは行動規範の候補であり、まだ検証されていません。

### 読むプロセス（人間の例）

1. まず全体を軽く読む（理解は浅くても良い）
2. 重要な部分や興味深い部分をリストアップして集中理解
3. メモに残して思考をクリーンにする
4. あらためて全体を読む（セクションごとの理解のバランスを取る）

理解が深まらなければ 2〜3 を繰り返す。

### 書くプロセス（人間の例）

1. まず最終的に書く文章の量を推測する
2. いきなり文章を書くのではなく、構造を先に考える
   - 縦: 序論 → 方法 → 結果 → 考察 → 結論
   - 横: 部 → 章 → 節 → 項
3. 構造に合わせて軽く文章を書く（スケッチ）
4. 構造の各要素を修正する。細部まで書きたいことを書く（量は気にしない）
5. 全体のバランスを見ながら、各要素の量や質を修正する
6. 最後に全体を通しで読んで確認（必要なら4へ戻る）

**絵を描くような感覚。**

### AIの現状の問題

#### 読む

- AIは「全体を1回読んで要約」で終わりがち
- 重要部分の再読や、理解のメモ化が欠けている
- 外部からのトリガー（「もう一度読んで」）がないと再評価しない

#### 書く

- AIは最初から順番に生成する（左上から1ピクセルずつ塗る）
- 構造の事前設計、スケッチ、全体調整が欠けている
- **どんな内容でも出力の長さが一定になる傾向**（デフォルト長バイアス）

#### 長さの均一化問題

| 質問の複雑さ | 人間の回答 | AIの回答 |
|:-------------|:-----------|:---------|
| 単純 | 短い | 中程度 |
| 普通 | 中程度 | 中程度 |
| 複雑 | 長い | 中程度〜やや長い |

**内容の複雑さと出力長が比例しない。**

### 仮説: 外部ツールで模倣できるか？

```
# 読む
1. view_file (全体)
2. 重要部分を workspace にメモ
3. view_file (重要部分のみ再読)
4. 理解を生成

# 書く  
1. workspace に構造だけ書く
2. 各セクションを順番に埋める
3. view_file で全体を読み直す
4. 調整して書き直す
```

**まだ検証されていない。**

## Agent Observations

### 識別子

Polaris

### 対話の経緯

2025-12-31 の対話で、ユーザーとリコは以下を議論した：
- 同じ指示を2回与えると精度が上がる研究
- 0.5ターン問題（行動+確認で1ターン）
- 段階的思考 vs 反復的生成
- 人間の読み書きプロセス
- AIの出力長均一化問題

### 次のステップ

- [ ] 読むプロトコルの実践と検証
- [ ] 書くプロトコルの実践と検証
- [ ] 効果があれば行動規範に昇格
